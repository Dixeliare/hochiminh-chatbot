from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from .services.enhanced_rag_service import EnhancedRAGService

app = FastAPI(title="Enhanced HCM Thought Chatbot API", version="2.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kh·ªüi t·∫°o Enhanced RAG service
rag_service = EnhancedRAGService()

# Models
class QuestionRequest(BaseModel):
    question: str

class EnhancedChatResponse(BaseModel):
    answer: str
    sources: list = []
    confidence: int = 0
    last_updated: str = None

@app.on_event("startup")
async def startup_event():
    """Kh·ªüi t·∫°o enhanced knowledge base"""
    print("üöÄ Starting Enhanced HCM Chatbot API...")
    rag_service.update_knowledge_base(force_update=True)
    print("‚úÖ Enhanced Server ready!")

@app.get("/")
async def root():
    return {"message": "Enhanced HCM Thought Chatbot API", "version": "2.0.0", "status": "running"}

@app.get("/health")
async def health_check():
    stats = rag_service.get_stats()
    return {"status": "healthy", "stats": stats}

@app.post("/chat", response_model=EnhancedChatResponse)
async def enhanced_chat(request: QuestionRequest):
    """Enhanced chat endpoint v·ªõi source citation"""
    try:
        if not request.question.strip():
            raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")

        # Fallback response khi quota h·∫øt
        try:
            # Generate enhanced response
            result = rag_service.generate_response_with_sources(request.question)

            return EnhancedChatResponse(
                answer=result["answer"],
                sources=result["sources"],
                confidence=result["confidence"],
                last_updated=result.get("last_updated", "2024-01-01")
            )
        except Exception as rag_error:
            print(f"RAG service error: {rag_error}")
            # Fallback response
            import google.generativeai as genai
            import os
            genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
            model = genai.GenerativeModel('gemini-2.5-flash')

            prompt = f"""
            C√¢u h·ªèi v·ªÅ t∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh: {request.question}

            H√£y tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c v·ªÅ t∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh, bao g·ªìm:
            - ƒê·ªôc l·∫≠p d√¢n t·ªôc
            - Ch·ªß nghƒ©a x√£ h·ªôi
            - ƒê·∫°o ƒë·ª©c c√°ch m·∫°ng
            - D√¢n ch·ªß
            - ƒêo√†n k·∫øt d√¢n t·ªôc
            """

            response = model.generate_content(prompt)

            return EnhancedChatResponse(
                answer=response.text,
                sources=["Ki·∫øn th·ª©c chung v·ªÅ t∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh"],
                confidence=75,
                last_updated="2024-01-01"
            )

    except Exception as e:
        print(f"Error in enhanced chat endpoint: {e}")
        raise HTTPException(status_code=500, detail="L·ªói server, vui l√≤ng th·ª≠ l·∫°i")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
